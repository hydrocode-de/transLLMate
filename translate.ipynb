{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Translate script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from transllmate.translator import Translator\n",
    "\n",
    "translator = Translator(db='./output/codebase_v1.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage:\n",
      "  fabric [OPTIONS]\n",
      "\n",
      "Application Options:\n",
      "  -p, --pattern=            Choose a pattern from the available patterns\n",
      "  -v, --variable=           Values for pattern variables, e.g. -v=#role:expert\n",
      "                            -v=#points:30\n",
      "  -C, --context=            Choose a context from the available contexts\n",
      "      --session=            Choose a session from the available sessions\n",
      "  -a, --attachment=         Attachment path or URL (e.g. for OpenAI image\n",
      "                            recognition messages)\n",
      "  -S, --setup               Run setup for all reconfigurable parts of fabric\n",
      "  -t, --temperature=        Set temperature (default: 0.7)\n",
      "  -T, --topp=               Set top P (default: 0.9)\n",
      "  -s, --stream              Stream\n",
      "  -P, --presencepenalty=    Set presence penalty (default: 0.0)\n",
      "  -r, --raw                 Use the defaults of the model without sending chat\n",
      "                            options (like temperature etc.) and use the user\n",
      "                            role instead of the system role for patterns.\n",
      "  -F, --frequencypenalty=   Set frequency penalty (default: 0.0)\n",
      "  -l, --listpatterns        List all patterns\n",
      "  -L, --listmodels          List all available models\n",
      "  -x, --listcontexts        List all contexts\n",
      "  -X, --listsessions        List all sessions\n",
      "  -U, --updatepatterns      Update patterns\n",
      "  -c, --copy                Copy to clipboard\n",
      "  -m, --model=              Choose model\n",
      "      --modelContextLength= Model context length (only affects ollama)\n",
      "  -o, --output=             Output to file\n",
      "      --output-session      Output the entire session (also a temporary one) to\n",
      "                            the output file\n",
      "  -n, --latest=             Number of latest patterns to list (default: 0)\n",
      "  -d, --changeDefaultModel  Change default model\n",
      "  -y, --youtube=            YouTube video or play list \"URL\" to grab\n",
      "                            transcript, comments from it and send to chat or\n",
      "                            print it put to the console and store it in the\n",
      "                            output file\n",
      "      --playlist            Prefer playlist over video if both ids are present\n",
      "                            in the URL\n",
      "      --transcript          Grab transcript from YouTube video and send to chat\n",
      "                            (it used per default).\n",
      "      --comments            Grab comments from YouTube video and send to chat\n",
      "  -g, --language=           Specify the Language Code for the chat, e.g. -g=en\n",
      "                            -g=zh\n",
      "  -u, --scrape_url=         Scrape website URL to markdown using Jina AI\n",
      "  -q, --scrape_question=    Search question using Jina AI\n",
      "  -e, --seed=               Seed to be used for LMM generation\n",
      "  -w, --wipecontext=        Wipe context\n",
      "  -W, --wipesession=        Wipe session\n",
      "      --printcontext=       Print context\n",
      "      --printsession=       Print session\n",
      "      --readability         Convert HTML input into a clean, readable view\n",
      "      --input-has-vars      Apply variables to user input\n",
      "      --dry-run             Show what would be sent to the model without\n",
      "                            actually sending it\n",
      "      --serve               Serve the Fabric Rest API\n",
      "      --address=            The address to bind the REST API (default: :8080)\n",
      "      --version             Print current version\n",
      "\n",
      "Help Options:\n",
      "  -h, --help                Show this help message\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cd {translator.fabric_path} && docker compose run --rm -T fabric -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go for each file that does not yet exist\n",
    "for struct_id in tqdm(translator.db.structs.df.index.values.tolist()):\n",
    "    # check if this already exists\n",
    "    if translator.has_id(struct_id):\n",
    "        continue\n",
    "\n",
    "    # run the LLM\n",
    "    body = translator.translate(id=struct_id, stream=False)\n",
    "    if len(body) == 0:\n",
    "        raise RuntimeError(f\"Structure ID={struct_id} could not be translated: empty body\")\n",
    "    translator.save_translation(id=struct_id, body=body)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
